



# FastAPI LangChain OpenAI Chat API

This project is a FastAPI application that integrates with LangChain and OpenAI to provide a chat API. It allows users to send chat messages and receive responses generated by the OpenAI  model.

## Features

- **FastAPI**: A modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.
- **LangChain**: A library for chaining together multiple language models.
- **OpenAI**: Integration with OpenAI's GPT models for generating chat responses.
- **CORS Middleware**: Allows cross-origin requests from any origin.

## Installation

1. Clone the repository:

   ```sh
   git clone https://github.com/Tencent-RTC/trtc-conversation-ai-example
   cd trtc-conversation-ai-example/llm_custom_memory
   ```

2. Install the required dependencies:
   ```sh
   pip install -r requirements.txt
   ```

3. Set up your environment variables by creating a `.env` file in the root directory with your OpenAI API key:
   ```
   OPENAI_API_KEY=your_openai_api_key
   OPENAI_API_BASE=https://api.deepseek.com // your openai api base
   ```

## Usage

1. Run the FastAPI application:
   ```sh
   uvicorn main:app --host 0.0.0.0 --port 8000
   ```

2. Access the API documentation at `http://localhost:8000/docs` to interact with the endpoints.

## Endpoints

### POST /v1/chat/completions

Sends a chat request to the OpenAI model and returns the generated response.

**Request Body**:
```json
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "Who won the world series in 2020?"
    }
  ],
  "temperature": 0.7
}
```

**Response**:
```json
{
  "id": "chatcmpl-12345678",
  "object": "chat.completion",
  "created": 1609459200,
  "model": "gpt-3.5-turbo",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "The Los Angeles Dodgers won the World Series in 2020."
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": -1,
    "completion_tokens": -1,
    "total_tokens": -1
  }
}
```

## Error Handling

The API handles errors by raising HTTP exceptions with a status code of 500 and the error detail in the response.

## Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

## License

[MIT](https://choosealicense.com/licenses/mit/)
